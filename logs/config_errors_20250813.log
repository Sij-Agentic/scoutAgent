2025-08-13 00:22:41 - config - ERROR - manager.py:179 - generate() - Error generating response with ollama: Ollama request timed out after 60s
2025-08-13 00:22:41 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Ollama request timed out after 60s
2025-08-13 00:22:41 - config - ERROR - screener.py:275 - plan() - Error in ScreenerAgent plan: Ollama request timed out after 60s
2025-08-13 00:23:42 - config - ERROR - manager.py:179 - generate() - Error generating response with ollama: Ollama request timed out after 60s
2025-08-13 00:23:42 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Ollama request timed out after 60s
2025-08-13 00:23:42 - config - ERROR - screener.py:325 - think() - Error in ScreenerAgent think: Ollama request timed out after 60s
2025-08-13 00:24:33 - config - ERROR - screener.py:240 - extract_json_from_markdown() - Failed to extract valid JSON from LLM response
2025-08-13 00:24:35 - config - ERROR - screener.py:240 - extract_json_from_markdown() - Failed to extract valid JSON from LLM response
2025-08-13 00:25:29 - config - ERROR - validator.py:364 - act() - Error executing validation: ValidatorOutput.__init__() missing 3 required positional arguments: 'result', 'metadata', and 'logs'
2025-08-13 00:26:33 - config - ERROR - manager.py:179 - generate() - Error generating response with ollama: Ollama request timed out after 60s
2025-08-13 00:26:33 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Ollama request timed out after 60s
2025-08-13 00:26:33 - config - ERROR - builder.py:316 - think() - Error analyzing market gaps: Ollama request timed out after 60s
2025-08-13 00:27:34 - config - ERROR - manager.py:179 - generate() - Error generating response with ollama: Ollama request timed out after 60s
2025-08-13 00:27:34 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Ollama request timed out after 60s
2025-08-13 00:27:34 - config - ERROR - builder.py:438 - act() - Error generating solution prototypes: Ollama request timed out after 60s
2025-08-13 00:31:37 - config - ERROR - screener.py:240 - extract_json_from_markdown() - Failed to extract valid JSON from LLM response
2025-08-13 00:32:28 - config - ERROR - screener.py:240 - extract_json_from_markdown() - Failed to extract valid JSON from LLM response
2025-08-13 00:33:28 - config - ERROR - manager.py:179 - generate() - Error generating response with ollama: Ollama request timed out after 60s
2025-08-13 00:33:28 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Ollama request timed out after 60s
2025-08-13 00:33:28 - config - ERROR - screener.py:325 - think() - Error in ScreenerAgent think: Ollama request timed out after 60s
2025-08-13 00:33:52 - config - ERROR - screener.py:240 - extract_json_from_markdown() - Failed to extract valid JSON from LLM response
2025-08-13 00:35:15 - config - ERROR - manager.py:179 - generate() - Error generating response with ollama: Ollama request timed out after 60s
2025-08-13 00:35:15 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Ollama request timed out after 60s
2025-08-13 00:35:15 - config - ERROR - validator.py:376 - act() - Error executing validation: Ollama request timed out after 60s
2025-08-13 14:39:50 - config - ERROR - manager.py:395 - initialize_llm_backends() - Failed to initialize Claude backend: Anthropic library not available. Install with: pip install anthropic
2025-08-13 14:39:50 - config - ERROR - manager.py:411 - initialize_llm_backends() - Failed to initialize Gemini backend: Google GenerativeAI library not available. Install with: pip install google-generativeai
2025-08-13 14:41:35 - config - ERROR - manager.py:395 - initialize_llm_backends() - Failed to initialize Claude backend: Anthropic library not available. Install with: pip install anthropic
2025-08-13 14:41:35 - config - ERROR - manager.py:411 - initialize_llm_backends() - Failed to initialize Gemini backend: Google GenerativeAI library not available. Install with: pip install google-generativeai
2025-08-13 14:41:38 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Backend not available: gemini
2025-08-13 14:41:38 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:41:39 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Backend not available: gemini
2025-08-13 14:44:26 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:44:26 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:44:26 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:26 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:26 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:27 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:44:27 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:44:27 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:27 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:27 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:28 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:28 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:28 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:29 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:29 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:29 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:30 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:30 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:30 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:31 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:31 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:31 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:31 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:44:31 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:44:31 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:13 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:48:13 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:48:13 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:13 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:13 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:14 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:48:14 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:48:14 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:14 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:14 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:15 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:48:15 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:48:15 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:15 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:15 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:19 - config - ERROR - base.py:161 - _retry_with_backoff() - All 3 attempts failed
2025-08-13 14:48:19 - config - ERROR - openai.py:141 - generate() - Error generating response: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:19 - config - ERROR - manager.py:179 - generate() - Error generating response with openai: OpenAI generation failed: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:19 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: OpenAI generation failed: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:19 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:19 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:19 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:24 - config - ERROR - base.py:161 - _retry_with_backoff() - All 3 attempts failed
2025-08-13 14:48:24 - config - ERROR - openai.py:141 - generate() - Error generating response: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:24 - config - ERROR - manager.py:179 - generate() - Error generating response with openai: OpenAI generation failed: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:24 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: OpenAI generation failed: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:24 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:24 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:24 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:28 - config - ERROR - base.py:161 - _retry_with_backoff() - All 3 attempts failed
2025-08-13 14:48:28 - config - ERROR - openai.py:141 - generate() - Error generating response: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:28 - config - ERROR - manager.py:179 - generate() - Error generating response with openai: OpenAI generation failed: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:28 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: OpenAI generation failed: Error code: 404 - {'error': {'message': 'The model `gemini-2.5-flash` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-08-13 14:48:28 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:28 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:28 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:29 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:48:29 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:48:29 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:32 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:32 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:32 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:33 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:33 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:33 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:35 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:35 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:35 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:36 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:36 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:36 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:37 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:59:37 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:59:37 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:37 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:37 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:37 - config - ERROR - manager.py:179 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:59:37 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 14:59:37 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:37 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:37 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:40 - config - ERROR - gemini.py:189 - stream_generate() - Error streaming response: object async_generator can't be used in 'await' expression
2025-08-13 14:59:40 - config - ERROR - manager.py:215 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 14:59:40 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: object async_generator can't be used in 'await' expression
2025-08-13 15:13:09 - config - ERROR - manager.py:201 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:13:09 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:31:40 - config - ERROR - manager.py:201 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:31:40 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:32:42 - config - ERROR - manager.py:201 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:32:42 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:44:30 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:30 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:30 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:32 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:32 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:32 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:33 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:33 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:33 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:35 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:35 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:35 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:36 - config - ERROR - manager.py:214 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:44:36 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:44:37 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:37 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:37 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:39 - config - ERROR - manager.py:214 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:44:39 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:44:40 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:40 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:40 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:44 - config - ERROR - gemini.py:188 - stream_generate() - Error streaming response: async generator raised StopIteration
2025-08-13 15:44:44 - config - ERROR - manager.py:250 - stream_generate() - Error streaming response with gemini: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:44:44 - config - ERROR - utils.py:313 - llm_stream_generate() - Error in LLM streaming: Gemini streaming failed: async generator raised StopIteration
2025-08-13 15:48:54 - config - ERROR - manager.py:214 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:48:54 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:49:00 - config - ERROR - manager.py:214 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:49:00 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:49:02 - config - ERROR - manager.py:214 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:49:02 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:49:04 - config - ERROR - manager.py:214 - generate() - Error generating response with gemini: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
2025-08-13 15:49:04 - config - ERROR - utils.py:259 - llm_generate() - Error in LLM generation: Gemini rate limit exceeded: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.
