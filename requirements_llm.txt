# Multi-Backend LLM Abstraction Layer Requirements
# Install with: pip install -r requirements_llm.txt

# Core async HTTP client for Ollama backend
aiohttp

# OpenAI backend
openai

# Anthropic Claude backend  
anthropic

# Google Gemini backend
google-generativeai

# Enhanced JSON parsing and validation
pydantic

# Better async utilities
asyncio-throttle

# Rate limiting
aiolimiter

# Retry utilities with exponential backoff
tenacity

# Better logging for LLM operations
structlog
