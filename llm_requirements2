# Multi-Backend LLM Abstraction Layer Requirements
# Install with: pip install -r requirements_llm.txt

# Core async HTTP client for Ollama backend
aiohttp>=3.8.0

# OpenAI backend
openai>=1.0.0

# Anthropic Claude backend  
anthropic>=0.7.0

# Google Gemini backend
google-generativeai>=0.3.0

# Optional: Enhanced JSON parsing and validation
pydantic>=2.0.0

# Optional: Better async utilities
asyncio-throttle>=1.0.0

# Optional: Rate limiting
aiolimiter>=1.1.0

# Optional: Retry utilities with exponential backoff
tenacity>=8.0.0

# Optional: Better logging for LLM operations
structlog>=23.0.0
